<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>selection.classification API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>selection.classification</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="selection.classification.ClassificationCostComputer"><code class="flex name class">
<span>class <span class="ident">ClassificationCostComputer</span></span>
<span>(</span><span>input_costs, output_costs, tokenizers=None, tokenize=True, n_output_tokens=1, constant_cost=False, store_all=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the Classification Computer object.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_costs</code></strong> :&ensp;<code>list</code></dt>
<dd>The input costs per token for each model.</dd>
<dt><strong><code>output_costs</code></strong> :&ensp;<code>list</code></dt>
<dd>The output costs per token for each model.</dd>
<dt><strong><code>tokenizers</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The tokenizers for each model. Defaults to None.</dd>
<dt><strong><code>tokenize</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to tokenize. Defaults to True.</dd>
<dt><strong><code>n_output_tokens</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of output tokens. Defaults to 1.</dd>
<dt><strong><code>constant_cost</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to always output constant costs for each model. Defaults to False.</dd>
<dt><strong><code>store_all</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to store all predictions. Speeds up prediction at the cost of memory.
Defaults to False.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClassificationCostComputer(BaseCostComputer):
    def __init__(self, input_costs, output_costs, tokenizers=None, 
                 tokenize=True, n_output_tokens=1, 
                 constant_cost=False, store_all=False):
        &#34;&#34;&#34;
        Initialize the Classification Computer object.

        Args:
            input_costs (list): The input costs per token for each model.
            output_costs (list): The output costs per token for each model.
            tokenizers (list, optional): The tokenizers for each model. Defaults to None.
            tokenize (bool, optional): Whether to tokenize. Defaults to True.
            n_output_tokens (int, optional): The number of output tokens. Defaults to 1.
            constant_cost (bool, optional): Whether to always output constant costs for each model. Defaults to False.
            store_all (bool, optional): Whether to store all predictions. Speeds up prediction at the cost of memory. 
                                        Defaults to False.
        &#34;&#34;&#34;
        super().__init__()
        self.input_costs = input_costs
        self.output_costs = output_costs
        self.tokenizers = tokenizers
        self.tokenize = tokenize
        self.n_output_tokens = n_output_tokens
        self.constant_cost = constant_cost
        self.store_all = store_all
        self.computed_costs = []
        assert tokenizers is not None or not tokenize

    def fit(self, questions, model_answers, measure=None):
        self.constant_costs = []
        for model in range(len(model_answers[0])):
            self.constant_costs.append(
                np.mean(measure[:, model])
            )
            self.computed_costs.append(dict())

    def predict(self, questions, model_answers):
        length_models = len(model_answers[0])

        all_costs = []
        for model in range(length_models):
            costs = []
            for question in questions:
                if not isinstance(question, str):
                    question = question[0]
                if (self.training or self.store_all) and question in self.computed_costs[model]:
                    costs.append(self.computed_costs[model][question])
                    continue
                elif not self.tokenize:
                    tokenized_question = question
                else:
                    tokenized_question = self.tokenizers[model]([question], padding=False)[&#39;input_ids&#39;][0]

                if self.constant_cost:
                    cost = self.constant_costs[model]
                else:
                    cost = self.input_costs[model] * len(tokenized_question)
                    cost += self.output_costs[model] * self.n_output_tokens # one output token
                costs.append(cost)
                if self.training or self.store_all:
                    self.computed_costs[model][question] = cost

            all_costs.append(costs)
        return np.array(all_costs).T</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="selection.cost_computer.BaseCostComputer" href="cost_computer.html#selection.cost_computer.BaseCostComputer">BaseCostComputer</a></li>
<li><a title="selection.base_computer.BaseComputer" href="base_computer.html#selection.base_computer.BaseComputer">BaseComputer</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="selection.cost_computer.BaseCostComputer" href="cost_computer.html#selection.cost_computer.BaseCostComputer">BaseCostComputer</a></b></code>:
<ul class="hlist">
<li><code><a title="selection.cost_computer.BaseCostComputer.fit" href="base_computer.html#selection.base_computer.BaseComputer.fit">fit</a></code></li>
<li><code><a title="selection.cost_computer.BaseCostComputer.is_independent" href="base_computer.html#selection.base_computer.BaseComputer.is_independent">is_independent</a></code></li>
<li><code><a title="selection.cost_computer.BaseCostComputer.predict" href="cost_computer.html#selection.cost_computer.BaseCostComputer.predict">predict</a></code></li>
<li><code><a title="selection.cost_computer.BaseCostComputer.trigger_training" href="base_computer.html#selection.base_computer.BaseComputer.trigger_training">trigger_training</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="selection.classification.ClassificationQualityComputer"><code class="flex name class">
<span>class <span class="ident">ClassificationQualityComputer</span></span>
<span>(</span><span>model_class=sklearn.linear_model._logistic.LogisticRegression, n_highest_include=1, require_constant_not_run=False, question_indicator='Question:', answer_indicator='Answer:', remove_options=['\nA:', '\nA.'], add_entropy=True, add_js_divergence=True, add_equal_argmax=True, max_depth=None, n_samples=100, store_all=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Initializes the ClassificationSelection object.</p>
<pre><code>    Args:
        model_class (class): The class of the prediction model to be used. Default is LogisticRegression.
        n_highest_include (int): The number of highest class probabilities to include in the features. 
                                Default is 1.
        require_constant_not_run (bool): Whether to require constant predictions for uncomputed models. 
                                        Default is False.
        question_indicator (str): The indicator for the "Question" part of a classification question. 
                                    Used for filtering and computing question length.
                                    Default is 'Question:'.
        answer_indicator (str): The indicator for the "Answer" part of the classification question. 
                                Used for filtering and computing question length.
                                Default is 'Answer:'.
        remove_options (list): The indicators of the options to remove from the text. 
                                Default is ['
</code></pre>
<p>A:', '
A.'].
add_entropy (bool): Whether to add entropy as feature. Default is True.
add_js_divergence (bool): Whether to add Jensen-Shannon divergence between model answers as feature. Default is True.
add_equal_argmax (bool): Whether to add equal prediction between model answers as feature. Default is True.
max_depth (int): The maximum depth for the cascade router. Default is None.
n_samples (int): The number of samples to compute max(q_1, &hellip;, q_n). Default is 100.
store_all (bool): Whether to store all results.
Speeds up prediction at the cost of memory.
Default is False.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClassificationQualityComputer(BaseQualityComputer):
    def __init__(self, model_class=LogisticRegression, 
                 n_highest_include=1, require_constant_not_run=False, 
                 question_indicator=r&#39;Question:&#39;, answer_indicator=r&#39;Answer:&#39;, 
                 remove_options=[&#39;\nA:&#39;, &#39;\nA.&#39;], 
                 add_entropy=True, add_js_divergence=True, 
                 add_equal_argmax=True, max_depth=None, 
                 n_samples=100, store_all=False):
        &#34;&#34;&#34;
        Initializes the ClassificationSelection object.

        Args:
            model_class (class): The class of the prediction model to be used. Default is LogisticRegression.
            n_highest_include (int): The number of highest class probabilities to include in the features. 
                                    Default is 1.
            require_constant_not_run (bool): Whether to require constant predictions for uncomputed models. 
                                            Default is False.
            question_indicator (str): The indicator for the &#34;Question&#34; part of a classification question. 
                                        Used for filtering and computing question length.
                                        Default is &#39;Question:&#39;.
            answer_indicator (str): The indicator for the &#34;Answer&#34; part of the classification question. 
                                    Used for filtering and computing question length.
                                    Default is &#39;Answer:&#39;.
            remove_options (list): The indicators of the options to remove from the text. 
                                    Default is [&#39;\nA:&#39;, &#39;\nA.&#39;].
            add_entropy (bool): Whether to add entropy as feature. Default is True.
            add_js_divergence (bool): Whether to add Jensen-Shannon divergence between model answers as feature. Default is True.
            add_equal_argmax (bool): Whether to add equal prediction between model answers as feature. Default is True.
            max_depth (int): The maximum depth for the cascade router. Default is None.
            n_samples (int): The number of samples to compute max(q_1, ..., q_n). Default is 100.
            store_all (bool): Whether to store all results. 
                            Speeds up prediction at the cost of memory.
                            Default is False.
        &#34;&#34;&#34;
        super().__init__(n_samples=n_samples)
        self.model_class = model_class
        self.models = None
        self.n_highest_include = n_highest_include
        self.sigma_per_n_models_run = None
        self.require_constant_not_run = require_constant_not_run
        self.constant_qualities = []
        self.question_indicator = question_indicator
        self.answer_indicator = answer_indicator
        self.remove_options = remove_options
        self.min_length = None
        self.max_length = None
        self.add_entropy = add_entropy
        self.add_js_divergence = add_js_divergence
        self.add_equal_argmax = add_equal_argmax
        self.max_depth = max_depth
        self.store_all = store_all
        self.lookup_embeddings = None
        self.question_predictions = dict()

    @property
    def is_independent(self):
        return False

    def entropy(self, p):
        &#34;&#34;&#34;
        Calculate the entropy of a probability distribution.

        Args:
            p (numpy.ndarray): The probability distribution.

        Returns:
        float: The entropy value.
        &#34;&#34;&#34;
        return -np.sum(p * np.log2(np.maximum(p, 1e-16)))
    
    def kl_divergence(self, p, q):
        &#34;&#34;&#34;
        Calculates the Kullback-Leibler divergence between two probability distributions.

        Args:
            p (numpy.ndarray): The first probability distribution.
            q (numpy.ndarray): The second probability distribution.

        Returns:
            float: The Kullback-Leibler divergence between p and q.
        &#34;&#34;&#34;
        return np.sum(p * np.log2(np.maximum(p, 1e-16) / np.maximum(q, 1e-16)))
    
    def js_divergence(self, p, q):
        &#34;&#34;&#34;
        Calculates the Jensen-Shannon divergence between two probability distributions.

        Args:
            p: numpy array or list, representing the first probability distribution.
            q: numpy array or list, representing the second probability distribution.

        Returns:
            js_div: float, the Jensen-Shannon divergence between p and q.
        &#34;&#34;&#34;
        m = (p + q) / 2
        return (self.kl_divergence(p, m) + self.kl_divergence(q, m)) / 2
    
    def parse_question(self, question, remove_options=True):
        &#34;&#34;&#34;
        Parses the given question and returns the extracted question text.

        Args:
            question (str or list): The question to be parsed. 
                                    If a list is provided, the first element will be used.
            remove_options (bool): Flag indicating whether to remove options from the question. 
                                    Default is True.

        Returns:
            str: The extracted question text.
        &#34;&#34;&#34;
        if not isinstance(question, str):
            question = question[0]
        question = question.split(self.question_indicator)[-1]
        if self.remove_options is not None and remove_options:
            for remove_option in self.remove_options:
                question = question.split(remove_option)[0].strip()
        question = question.split(self.answer_indicator)[0].strip()
        return question

    def fit(self, questions, model_answers, measure):
        self.min_length = min([len(self.parse_question(question)) for question in questions])
        self.max_length = max([len(self.parse_question(question)) for question in questions])
        n_models = len(model_answers[0])
        self.models = [dict() for _ in range(n_models)]
        X, X_all_models, y, for_model, all_models_run = self.prepare_data(questions, model_answers, measure, n_models)
        y_pred_all = np.zeros((len(X) // n_models, n_models))
        y_pred_all_models = np.zeros((len(X) // n_models, n_models))

        for model in range(n_models):
            models_to_fit = np.unique(all_models_run)
            for models_run_string in tqdm(models_to_fit, desc=f&#39;Model {model}&#39;):
                self.models[model][models_run_string] = self.model_class()
                indices_run = [i for i in range(len(X)) 
                                if all_models_run[i] == models_run_string and for_model[i] == model]
                X_here = np.array([X[i] for i in indices_run])
                y_here = np.array([y[i] for i in indices_run])
                self.models[model][models_run_string].fit(X=X_here, y=y_here)
                y_pred = self.models[model][models_run_string].predict_proba(X_here)[:, 1]
                
                indices_pred_all = [i // n_models for i in indices_run]
                y_pred_all[indices_pred_all, model] = y_pred

            indices_all = [i for i in range(len(X)) if for_model[i] == model]
            y_pred_all_models[:, model] = self.predict_model(self.models[model][&#39;,&#39;.join([str(i) for i in range(n_models)])], X_all_models[indices_all])

        self.compute_sigma(n_models,  all_models_run, y_pred_all, 
                           y_pred_all_models, models_to_fit)

    def compute_sigma(self, n_models, all_models_run, 
                      y_pred_all, y_pred_all_models, models_to_fit):
        &#34;&#34;&#34;
        Compute the deviation of the predicted values from the actual values.

        Parameters:
            n_models (int): The number of models.
            all_n_models_run (numpy.ndarray): Array containing the number of models run for each iteration.
            all_models_run (numpy.ndarray): Array containing the models run for each iteration.
            y_pred_all (numpy.ndarray): Array containing the predicted values for all iterations.
            y_pred_all_models (numpy.ndarray): Array containing the predicted values for all models and iterations.
            models_to_fit (list): List of models to fit.
        &#34;&#34;&#34;
        all_models_run_single = np.array([all_models_run[i] 
                                          for i in range(0, len(all_models_run), n_models)])
        self.sigma_per_n_models_run = dict()
        for models_run_string in models_to_fit:
            diff = y_pred_all[all_models_run_single == models_run_string] - y_pred_all_models[all_models_run_single == models_run_string]
            self.sigma_per_n_models_run[models_run_string] = np.cov(diff.T)

    def prepare_data(self, questions, model_answers, measure, n_models):
        &#34;&#34;&#34;
        Prepare the data for fitting.
        Args:
            questions (list): List of questions.
            model_answers (list): List of model answers.
            measure (list): List of measures.
            n_models (int): Number of models.
        Returns:
            tuple: A tuple containing the following arrays:
                - X (ndarray): Input data for each model.
                - X_all_models (ndarray): Input data for all models.
                - y (ndarray): Output data.
                - for_model (ndarray): Model index for each data point.
                - all_models_run (ndarray): String representation of models used for each data point.
        &#34;&#34;&#34;
        X = []
        X_all_models = []
        y = []
        for_model = []
        all_models_run = []

        for model in range(n_models):
            self.constant_qualities.append(np.mean([measure[i][model] for i in range(len(questions))]))

        for i in range(len(questions)):
            for n_models_run in range(n_models + 1):
                if self.max_depth is not None and n_models &gt; n_models_run &gt; self.max_depth:
                    continue
                for models_run in itertools.combinations(range(n_models), n_models_run):
                    models_run_string = &#39;,&#39;.join([str(model) for model in sorted(models_run)])
                    
                    models_answers_sample = [answer if model in models_run else None 
                                             for model, answer in enumerate(model_answers[i])]
                    measure_sample = measure[i]
                    
                    for model in range(n_models):
                        X_sample, y_sample = self.generate_sample_input_output(questions[i], model, 
                                                                               n_models, 
                                                                               models_answers_sample, 
                                                                               measure_sample, i)
                        X_sample_all_models, _ = self.generate_sample_input_output(questions[i], model, 
                                                                                   n_models, 
                                                                                   model_answers[i], 
                                                                                   measure_sample, i)
                        y.append(y_sample)
                        X.append(X_sample)
                        X_all_models.append(X_sample_all_models)
                        all_models_run.append(models_run_string)
                        for_model.append(model)

        X_all_models = np.array(X_all_models)
        y = np.array(y)
        all_models_run = np.array(all_models_run)
        for_model = np.array(for_model)
        return X,X_all_models,y,for_model,all_models_run
    
    def predict_model(self, model, X):
        &#34;&#34;&#34;
        Predicts the target variable using the given model.

        Parameters:
            model (object): The trained model used for prediction.
            X (array-like): The input features for prediction.

        Returns:
            array-like: The predicted target variable values.
        &#34;&#34;&#34;
        return model.predict_proba(X)[:, 1]

    def predict(self, questions, model_answers):
        n_models = len(model_answers[0])
        n_models_answered = np.array([
            len([model_answer for model_answer in model_answers[i] if model_answer is not None]) 
            for i in range(len(questions))
        ])
        all_models_run_strings = np.array([&#39;,&#39;.join([str(i) for i in range(n_models) 
                                                     if model_answers[j][i] is not None]) 
                                            for j in range(len(questions))]) 
        y = np.zeros((len(questions), n_models))

        for model in range(n_models):
            y_model_done = np.zeros(len(questions)).astype(bool)
            if self.training or self.store_all:
                for i in range(len(questions)):
                    models_run = all_models_run_strings[i]
                    question = questions[i]
                    if not isinstance(question, str):
                        question = question[0]
                    question_prediction = self.question_predictions.get(model, 
                                                                        dict()).get(models_run, dict()).get(question, None)
                    if question_prediction is not None:
                        y[i, model] = question_prediction
                        y_model_done[i] = True
            
            y_model = np.zeros(np.count_nonzero(np.logical_not(y_model_done)))
            X_model = [self.generate_sample_input_output(questions[i], model, 
                                                         n_models, model_answers[i])[0] 
                        for i in range(len(questions)) if not y_model_done[i]]
            model_answers_here = [model_answers[i] for i in range(len(questions)) if not y_model_done[i]]
            models_run_strings = all_models_run_strings[np.logical_not(y_model_done)]
            for models_run_string in self.models[model].keys():
                indices = np.where(models_run_string == models_run_strings)[0]
                X = [X_model[i] for i in indices]
                if len(indices) == 0:
                    continue
                y_model[indices] = self.predict_model(self.models[model][models_run_string], X)

            if self.require_constant_not_run:
                for i in range(len(y_model)):
                    if model_answers_here[i][model] is None:
                        y_model[i] = self.constant_qualities[model]
            
            y[np.logical_not(y_model_done), model] = y_model

            if self.training or self.store_all:
                for i in range(len(questions)):
                    models_run = all_models_run_strings[i]
                    if model not in self.question_predictions:
                        self.question_predictions[model] = dict()
                    if models_run not in self.question_predictions.get(model, dict()):
                        self.question_predictions[model][models_run] = dict()
                    
                    question = questions[i]
                    if not isinstance(question, str):
                        question = question[0]
                    self.question_predictions[model][models_run][question] = y[i, model]
        return y, np.array([self.sigma_per_n_models_run[all_models_run_strings[i]] 
                                for i in range(len(questions))])

    def predict_n_answers(self, model_answers, n_models_answered, model, y_model, X_model, n_answers, model_answered):
        &#34;&#34;&#34;
        Predicts the answers for a given model and number of answers.
        Args:
            model_answers (list): List containing model answers.
            n_models_answered (numpy.ndarray): Array of the number of models answered for each question.
            model (int): Index of the model to predict the answers for.
            y_model (numpy.ndarray): Array of the model answers.
            X_model (list): List of input features for the model.
            n_answers (int): Number of answers to predict.
            model_answered (bool): Flag indicating whether the model has already answered.
        &#34;&#34;&#34;
        
        if model_answered:
            indices = np.where(np.logical_and(n_models_answered == n_answers, 
                                              [answer[model] is not None for answer in model_answers]))[0]
        else:
            indices = np.where(np.logical_and(n_models_answered == n_answers, 
                                              [answer[model] is None for answer in model_answers]))[0]
        X = [X_model[i] for i in indices]
        if len(indices) &gt; 0:
            y_model[indices] = self.predict_model(self.models[model][n_answers][model_answered], X)

    def base_features(self, question, index, model):
        &#34;&#34;&#34;
        Generate a list of base features for a given question, index, and model.

        Parameters:
           question (str or tuple): The question to generate features for. 
                                    If a tuple is provided, the first element is the question string 
                                    and the remaining elements are additional features.
            index (int or None): The index of the question in the training dataset. 
                                If None, the question is not in the dataset.
            model (str): The name of the model.

        Returns:
            features (list): A list of features for the given question, index, and model.
        &#34;&#34;&#34;
        features = []
        if not isinstance(question, str):
            question, additional_features = question[0], question[1:]
            features.extend(additional_features)

        question_here = self.parse_question(question, remove_options=False)
        n_options = sum([f&#39;\n{x}:&#39; in question or f&#39;\n{x}.&#39; in question_here for x in &#39;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#39;])
        features.append(1 / (max(n_options, 1)))
        return features

    def agreement_features(self, n_models, models_answers_sample):
        &#34;&#34;&#34;
        Calculates agreement features between models&#39; answers.

        Args:
            n_models (int): The number of models.
            models_answers_sample (list): A list of models&#39; answers.

        Returns:
            list: A list of agreement features.

        &#34;&#34;&#34;
        features = []
        for i in range(n_models):
            for j in range(i + 1, n_models):
                if models_answers_sample[i] is not None and models_answers_sample[j] is not None:
                    if self.add_js_divergence:
                        features.append(self.js_divergence(models_answers_sample[i], 
                                                           models_answers_sample[j]))
                    if self.add_equal_argmax:
                        features.append(float(np.argmax(models_answers_sample[i]) == np.argmax(models_answers_sample[j])))
        return features

    def certainty_features(self, model, models_answers_sample):
        &#34;&#34;&#34;
        Calculate the certainty features for a given model and models_answers_sample.

        Parameters:
        - model: The index of the model for which to calculate the certainty features.
        - models_answers_sample: A list of model answers for each model.

        Returns:
        - A list of certainty features for the given model.

        Raises:
        - None.

        &#34;&#34;&#34;
        if models_answers_sample[model] is None:
            return []
        else:
            model_answer_highest = sorted(models_answers_sample[model], key=lambda x: -x)[:self.n_highest_include]
            if len(model_answer_highest) &lt; self.n_highest_include:
                for _ in range(self.n_highest_include - len(model_answer_highest)):
                    model_answer_highest.append(0)
            if self.add_entropy:
                model_answer_highest.append(self.entropy(models_answers_sample[model]))
            return model_answer_highest

    def generate_sample_input_output(self, question, model, n_models, models_answers_sample, 
                                     measure_sample=None, index=None):
        &#34;&#34;&#34;
        Generates a sample input and output for model selection.

        Args:
            question (str): The question for which the sample input and output are generated.
            model (int): The index of the model being evaluated.
            n_models (int): The total number of models.
            models_answers_sample (list): A list of model answers for the sample.
            measure_sample (list, optional): A list of measures for the sample. Defaults to None.
            index (int, optional): The index of the question. Defaults to None.

        Returns:
            tuple: A tuple containing the sample input and output.
        &#34;&#34;&#34;
        X_sample = []
        X_sample += self.base_features(question, index, model)
        X_sample += self.agreement_features(n_models, models_answers_sample)
        X_sample += self.certainty_features(model, models_answers_sample)
        if len(X_sample) == 0:
            X_sample = [0]

        if measure_sample is not None:
            return X_sample, measure_sample[model]
        return X_sample, None</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="selection.quality_computer.BaseQualityComputer" href="quality_computer.html#selection.quality_computer.BaseQualityComputer">BaseQualityComputer</a></li>
<li><a title="selection.base_computer.BaseComputer" href="base_computer.html#selection.base_computer.BaseComputer">BaseComputer</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="selection.open_form.OpenFormQualityComputer" href="open_form.html#selection.open_form.OpenFormQualityComputer">OpenFormQualityComputer</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="selection.classification.ClassificationQualityComputer.agreement_features"><code class="name flex">
<span>def <span class="ident">agreement_features</span></span>(<span>self, n_models, models_answers_sample)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates agreement features between models' answers.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_models</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of models.</dd>
<dt><strong><code>models_answers_sample</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of models' answers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>A list of agreement features.</dd>
</dl></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.base_features"><code class="name flex">
<span>def <span class="ident">base_features</span></span>(<span>self, question, index, model)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a list of base features for a given question, index, and model.</p>
<h2 id="parameters">Parameters</h2>
<p>question (str or tuple): The question to generate features for.
If a tuple is provided, the first element is the question string
and the remaining elements are additional features.
index (int or None): The index of the question in the training dataset.
If None, the question is not in the dataset.
model (str): The name of the model.</p>
<h2 id="returns">Returns</h2>
<p>features (list): A list of features for the given question, index, and model.</p></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.certainty_features"><code class="name flex">
<span>def <span class="ident">certainty_features</span></span>(<span>self, model, models_answers_sample)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the certainty features for a given model and models_answers_sample.</p>
<p>Parameters:
- model: The index of the model for which to calculate the certainty features.
- models_answers_sample: A list of model answers for each model.</p>
<p>Returns:
- A list of certainty features for the given model.</p>
<p>Raises:
- None.</p></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.compute_sigma"><code class="name flex">
<span>def <span class="ident">compute_sigma</span></span>(<span>self, n_models, all_models_run, y_pred_all, y_pred_all_models, models_to_fit)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the deviation of the predicted values from the actual values.</p>
<h2 id="parameters">Parameters</h2>
<p>n_models (int): The number of models.
all_n_models_run (numpy.ndarray): Array containing the number of models run for each iteration.
all_models_run (numpy.ndarray): Array containing the models run for each iteration.
y_pred_all (numpy.ndarray): Array containing the predicted values for all iterations.
y_pred_all_models (numpy.ndarray): Array containing the predicted values for all models and iterations.
models_to_fit (list): List of models to fit.</p></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.entropy"><code class="name flex">
<span>def <span class="ident">entropy</span></span>(<span>self, p)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the entropy of a probability distribution.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>p</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The probability distribution.</dd>
</dl>
<p>Returns:
float: The entropy value.</p></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.generate_sample_input_output"><code class="name flex">
<span>def <span class="ident">generate_sample_input_output</span></span>(<span>self, question, model, n_models, models_answers_sample, measure_sample=None, index=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a sample input and output for model selection.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>question</code></strong> :&ensp;<code>str</code></dt>
<dd>The question for which the sample input and output are generated.</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the model being evaluated.</dd>
<dt><strong><code>n_models</code></strong> :&ensp;<code>int</code></dt>
<dd>The total number of models.</dd>
<dt><strong><code>models_answers_sample</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of model answers for the sample.</dd>
<dt><strong><code>measure_sample</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>A list of measures for the sample. Defaults to None.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The index of the question. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>A tuple containing the sample input and output.</dd>
</dl></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.js_divergence"><code class="name flex">
<span>def <span class="ident">js_divergence</span></span>(<span>self, p, q)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the Jensen-Shannon divergence between two probability distributions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>p</code></strong></dt>
<dd>numpy array or list, representing the first probability distribution.</dd>
<dt><strong><code>q</code></strong></dt>
<dd>numpy array or list, representing the second probability distribution.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>js_div</code></dt>
<dd>float, the Jensen-Shannon divergence between p and q.</dd>
</dl></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.kl_divergence"><code class="name flex">
<span>def <span class="ident">kl_divergence</span></span>(<span>self, p, q)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the Kullback-Leibler divergence between two probability distributions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>p</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The first probability distribution.</dd>
<dt><strong><code>q</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>The second probability distribution.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>The Kullback-Leibler divergence between p and q.</dd>
</dl></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.parse_question"><code class="name flex">
<span>def <span class="ident">parse_question</span></span>(<span>self, question, remove_options=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Parses the given question and returns the extracted question text.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>question</code></strong> :&ensp;<code>str</code> or <code>list</code></dt>
<dd>The question to be parsed.
If a list is provided, the first element will be used.</dd>
<dt><strong><code>remove_options</code></strong> :&ensp;<code>bool</code></dt>
<dd>Flag indicating whether to remove options from the question.
Default is True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The extracted question text.</dd>
</dl></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.predict_model"><code class="name flex">
<span>def <span class="ident">predict_model</span></span>(<span>self, model, X)</span>
</code></dt>
<dd>
<div class="desc"><p>Predicts the target variable using the given model.</p>
<h2 id="parameters">Parameters</h2>
<p>model (object): The trained model used for prediction.
X (array-like): The input features for prediction.</p>
<h2 id="returns">Returns</h2>
<p>array-like: The predicted target variable values.</p></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.predict_n_answers"><code class="name flex">
<span>def <span class="ident">predict_n_answers</span></span>(<span>self, model_answers, n_models_answered, model, y_model, X_model, n_answers, model_answered)</span>
</code></dt>
<dd>
<div class="desc"><p>Predicts the answers for a given model and number of answers.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_answers</code></strong> :&ensp;<code>list</code></dt>
<dd>List containing model answers.</dd>
<dt><strong><code>n_models_answered</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Array of the number of models answered for each question.</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of the model to predict the answers for.</dd>
<dt><strong><code>y_model</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Array of the model answers.</dd>
<dt><strong><code>X_model</code></strong> :&ensp;<code>list</code></dt>
<dd>List of input features for the model.</dd>
<dt><strong><code>n_answers</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of answers to predict.</dd>
<dt><strong><code>model_answered</code></strong> :&ensp;<code>bool</code></dt>
<dd>Flag indicating whether the model has already answered.</dd>
</dl></div>
</dd>
<dt id="selection.classification.ClassificationQualityComputer.prepare_data"><code class="name flex">
<span>def <span class="ident">prepare_data</span></span>(<span>self, questions, model_answers, measure, n_models)</span>
</code></dt>
<dd>
<div class="desc"><p>Prepare the data for fitting.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>questions</code></strong> :&ensp;<code>list</code></dt>
<dd>List of questions.</dd>
<dt><strong><code>model_answers</code></strong> :&ensp;<code>list</code></dt>
<dd>List of model answers.</dd>
<dt><strong><code>measure</code></strong> :&ensp;<code>list</code></dt>
<dd>List of measures.</dd>
<dt><strong><code>n_models</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of models.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>A tuple containing the following arrays:
- X (ndarray): Input data for each model.
- X_all_models (ndarray): Input data for all models.
- y (ndarray): Output data.
- for_model (ndarray): Model index for each data point.
- all_models_run (ndarray): String representation of models used for each data point.</dd>
</dl></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="selection.quality_computer.BaseQualityComputer" href="quality_computer.html#selection.quality_computer.BaseQualityComputer">BaseQualityComputer</a></b></code>:
<ul class="hlist">
<li><code><a title="selection.quality_computer.BaseQualityComputer.fit" href="base_computer.html#selection.base_computer.BaseComputer.fit">fit</a></code></li>
<li><code><a title="selection.quality_computer.BaseQualityComputer.fit_covariances" href="quality_computer.html#selection.quality_computer.BaseQualityComputer.fit_covariances">fit_covariances</a></code></li>
<li><code><a title="selection.quality_computer.BaseQualityComputer.is_independent" href="base_computer.html#selection.base_computer.BaseComputer.is_independent">is_independent</a></code></li>
<li><code><a title="selection.quality_computer.BaseQualityComputer.predict" href="base_computer.html#selection.base_computer.BaseComputer.predict">predict</a></code></li>
<li><code><a title="selection.quality_computer.BaseQualityComputer.predict_covariances" href="quality_computer.html#selection.quality_computer.BaseQualityComputer.predict_covariances">predict_covariances</a></code></li>
<li><code><a title="selection.quality_computer.BaseQualityComputer.predict_supermodels" href="quality_computer.html#selection.quality_computer.BaseQualityComputer.predict_supermodels">predict_supermodels</a></code></li>
<li><code><a title="selection.quality_computer.BaseQualityComputer.trigger_training" href="base_computer.html#selection.base_computer.BaseComputer.trigger_training">trigger_training</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="selection" href="index.html">selection</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="selection.classification.ClassificationCostComputer" href="#selection.classification.ClassificationCostComputer">ClassificationCostComputer</a></code></h4>
</li>
<li>
<h4><code><a title="selection.classification.ClassificationQualityComputer" href="#selection.classification.ClassificationQualityComputer">ClassificationQualityComputer</a></code></h4>
<ul class="">
<li><code><a title="selection.classification.ClassificationQualityComputer.agreement_features" href="#selection.classification.ClassificationQualityComputer.agreement_features">agreement_features</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.base_features" href="#selection.classification.ClassificationQualityComputer.base_features">base_features</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.certainty_features" href="#selection.classification.ClassificationQualityComputer.certainty_features">certainty_features</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.compute_sigma" href="#selection.classification.ClassificationQualityComputer.compute_sigma">compute_sigma</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.entropy" href="#selection.classification.ClassificationQualityComputer.entropy">entropy</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.generate_sample_input_output" href="#selection.classification.ClassificationQualityComputer.generate_sample_input_output">generate_sample_input_output</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.js_divergence" href="#selection.classification.ClassificationQualityComputer.js_divergence">js_divergence</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.kl_divergence" href="#selection.classification.ClassificationQualityComputer.kl_divergence">kl_divergence</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.parse_question" href="#selection.classification.ClassificationQualityComputer.parse_question">parse_question</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.predict_model" href="#selection.classification.ClassificationQualityComputer.predict_model">predict_model</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.predict_n_answers" href="#selection.classification.ClassificationQualityComputer.predict_n_answers">predict_n_answers</a></code></li>
<li><code><a title="selection.classification.ClassificationQualityComputer.prepare_data" href="#selection.classification.ClassificationQualityComputer.prepare_data">prepare_data</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
