<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.1">
<title>selection.lambda_strategy API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>selection.lambda_strategy</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="selection.lambda_strategy.ConstantStrategy"><code class="flex name class">
<span>class <span class="ident">ConstantStrategy</span></span>
<span>(</span><span>max_lambda, n_iterations=20)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize a ConstantStrategy object.
Assumes that all values of lambda are the same and performs a binary search to find the optimal lambda.</p>
<p>Parameters:
- max_lambda (float): The maximum value for lambda.
- n_iterations (int, optional): The number of iterations. Default is 20.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConstantStrategy(Strategy):
    def __init__(self, max_lambda, n_iterations=20):
        &#34;&#34;&#34;
        Initialize a ConstantStrategy object.
        Assumes that all values of lambda are the same and performs a binary search to find the optimal lambda.

        Parameters:
        - max_lambda (float): The maximum value for lambda.
        - n_iterations (int, optional): The number of iterations. Default is 20.
        &#34;&#34;&#34;
        super().__init__()
        self.max_lambda = max_lambda
        self.n_iterations = n_iterations

    def compute_lambdas(self, current_optimal_lambdas, execute_function, cost_target, args_execute_function):
        logger.debug(&#34;Computing lambdas with constant strategy&#34;)
        lambda_min = (0, None, None)
        lambda_max = (self.max_lambda, None, None)

        max_lambda = self.max_lambda
        while max_lambda &lt; 1e10:
            lambdas = [max_lambda for _ in range(len(current_optimal_lambdas))]
            output_dict = execute_function(lambdas, *args_execute_function)
            cost = output_dict[&#39;cost&#39;]
            if cost &gt; cost_target:
                logger.info(f&#39;Max lambda {max_lambda} is too low, increasing max lambda&#39;)
                lambda_min = (max_lambda, cost, output_dict[&#39;quality&#39;])
                max_lambda *= 2
                lambda_max = (max_lambda, None, None)
            else:
                lambda_max = (max_lambda, cost, output_dict[&#39;quality&#39;])
                break

        # Do binary search to find the optimal lambda
        for _ in range(self.n_iterations):
            lambda_mid = (lambda_min[0] + lambda_max[0]) / 2
            logger.debug(f&#34;Lambda mid: {lambda_mid}&#34;)
            lambdas = [lambda_mid for _ in range(len(current_optimal_lambdas))]
            output_dict = execute_function(lambdas, *args_execute_function)
            cost = output_dict[&#39;cost&#39;]

            if cost &lt; cost_target:
                lambda_max = (lambda_mid, cost, output_dict[&#39;quality&#39;])
            else:
                lambda_min = (lambda_mid, cost, output_dict[&#39;quality&#39;])
            logger.debug(f&#34;Cost: {cost}&#34;)
            logger.debug(f&#34;Quality: {output_dict[&#39;quality&#39;]}&#34;)

        if lambda_max[2] is None:
            lambdas = [lambda_max[0] for _ in range(len(current_optimal_lambdas))]
            output_dict = execute_function(lambdas, *args_execute_function)
            lambda_max = (lambda_max[0], output_dict[&#39;cost&#39;], output_dict[&#39;quality&#39;])

        logger.info(f&#34;Final Lambda: {lambda_max[0]}&#34;)
        logger.info(f&#34;Final Cost: {lambda_max[1]}&#34;)
        logger.info(f&#34;Final Quality: {lambda_max[2]}&#34;)
        
        return [lambda_max[0] for _ in range(len(current_optimal_lambdas))], lambda_max[1], lambda_max[2]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="selection.lambda_strategy.Strategy" href="#selection.lambda_strategy.Strategy">Strategy</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="selection.lambda_strategy.Strategy" href="#selection.lambda_strategy.Strategy">Strategy</a></b></code>:
<ul class="hlist">
<li><code><a title="selection.lambda_strategy.Strategy.compute_lambdas" href="#selection.lambda_strategy.Strategy.compute_lambdas">compute_lambdas</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="selection.lambda_strategy.HyperoptStrategy"><code class="flex name class">
<span>class <span class="ident">HyperoptStrategy</span></span>
<span>(</span><span>max_lambda, n_searches=100, max_factor=4, from_scratch=False, optimize_max_depth=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the HyperoptStrategy object.
Uses the hyperopt library to optimize the lambda values.</p>
<p>Parameters:
- max_lambda (int): The maximum lambda value.
- n_searches (int, optional): The number of searches to perform. Defaults to 100.
- max_factor (int, optional): The maximum factor to increase the prior optimal lambdas by. Defaults to 4.
- from_scratch (bool, optional): Whether to start from scratch and ignore the prior optimal lambdas.
Defaults to False.
- optimize_max_depth (bool, optional): Whether to optimize the maximum depth. Defaults to False.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HyperoptStrategy(Strategy):
    def __init__(self, max_lambda, n_searches=100, max_factor=4, from_scratch=False, 
                optimize_max_depth=False):
        &#34;&#34;&#34;
        Initialize the HyperoptStrategy object.
        Uses the hyperopt library to optimize the lambda values.

        Parameters:
        - max_lambda (int): The maximum lambda value.
        - n_searches (int, optional): The number of searches to perform. Defaults to 100.
        - max_factor (int, optional): The maximum factor to increase the prior optimal lambdas by. Defaults to 4.
        - from_scratch (bool, optional): Whether to start from scratch and ignore the prior optimal lambdas. 
                                        Defaults to False.
        - optimize_max_depth (bool, optional): Whether to optimize the maximum depth. Defaults to False.
        &#34;&#34;&#34;
        super().__init__()
        self.max_lambda = max_lambda
        self.n_searches = n_searches
        self.max_factor = max_factor
        self.from_scratch = from_scratch
        self.optimize_max_depth = optimize_max_depth
        self.all_results = []

    def objective(self, lambdas, cost_init, lambda_tradeoff, execute_function, *args):
        if self.optimize_max_depth:
            lambdas, max_depth = lambdas[:-1], int(lambdas[-1])
            lambdas = [lambda_ if i &lt; max_depth else None for i, lambda_ in enumerate(lambdas)]
        output_dict = execute_function(lambdas, *args)
        output_dict[&#39;lambdas&#39;] = lambdas
        self.all_results.append(output_dict)
        return -output_dict[&#39;quality&#39;] + lambda_tradeoff * max(0, output_dict[&#39;cost&#39;] - cost_init)

    def compute_lambdas(self, current_optimal_lambdas, execute_function, cost_target, args_execute_function):
        logger.debug(&#34;Computing lambdas with hyperopt strategy&#34;)
        self.all_results = []
        space = []
        max_init_val = max([lambda_ for lambda_ in current_optimal_lambdas if lambda_ is not None])
        for i in range(len(current_optimal_lambdas)):
            if current_optimal_lambdas[i] is None and not self.optimize_max_depth:
                space.append(hp.choice(f&#39;lambda_{i}&#39;, [None]))
            else:
                max_val = max(0, (1 - self.max_factor) * max_init_val)
                if max_val == 0 or self.from_scratch or self.max_lambda == 1:
                    max_val = self.max_lambda
                space.append(hp.uniform(f&#39;lambda_{i}&#39;, 0, max_val))
        
        if self.optimize_max_depth:
            space.append(hp.choice(&#39;max_depth&#39;, [i for i in range(1, len(current_optimal_lambdas) + 1)]))

        results_init = execute_function(current_optimal_lambdas, *args_execute_function)
        cost_init = results_init[&#39;cost&#39;]
        lambda_tradeoff = results_init[&#39;quality&#39;] / cost_init
        objective = lambda x: self.objective(x, cost_init, lambda_tradeoff, execute_function, *args_execute_function)
        best = fmin(objective, space, algo=tpe.suggest, max_evals=self.n_searches, 
                    rstate= np.random.default_rng(0))
        all_results_low_cost = [result for result in self.all_results if result[&#39;cost&#39;] &lt; cost_target]
        if len(all_results_low_cost) == 0:
            return current_optimal_lambdas, cost_init, results_init[&#39;quality&#39;]
        best_lambda_index = np.argmax([result[&#39;quality&#39;] for result in all_results_low_cost])
        best_lambdas = all_results_low_cost[best_lambda_index][&#39;lambdas&#39;]
        cost_best = all_results_low_cost[best_lambda_index][&#39;cost&#39;]
        quality_best = all_results_low_cost[best_lambda_index][&#39;quality&#39;]
        logger.info(f&#34;Final Lambdas: {best_lambdas}&#34;)
        logger.info(f&#34;Final Cost: {cost_best}&#34;)
        logger.info(f&#34;Final Quality: {quality_best}&#34;)
        return best_lambdas, cost_best, quality_best</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="selection.lambda_strategy.Strategy" href="#selection.lambda_strategy.Strategy">Strategy</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="selection.lambda_strategy.HyperoptStrategy.objective"><code class="name flex">
<span>def <span class="ident">objective</span></span>(<span>self, lambdas, cost_init, lambda_tradeoff, execute_function, *args)</span>
</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="selection.lambda_strategy.Strategy" href="#selection.lambda_strategy.Strategy">Strategy</a></b></code>:
<ul class="hlist">
<li><code><a title="selection.lambda_strategy.Strategy.compute_lambdas" href="#selection.lambda_strategy.Strategy.compute_lambdas">compute_lambdas</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="selection.lambda_strategy.RepetitiveConstantStrategy"><code class="flex name class">
<span>class <span class="ident">RepetitiveConstantStrategy</span></span>
<span>(</span><span>max_lambda, n_iterations=20)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the RepetitiveConstantStrategy object.
Assumes that lambda values are of the form [lambda, &hellip;, lambda, None, &hellip;, None]
and performs a binary search to find the optimal lambda and number of None values.</p>
<p>Parameters:
- max_lambda (float): The maximum value for lambda.
- n_iterations (int, optional): The number of iterations. Default is 20.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RepetitiveConstantStrategy(Strategy):
    def __init__(self, max_lambda, n_iterations=20):
        &#34;&#34;&#34;
        Initialize the RepetitiveConstantStrategy object.
        Assumes that lambda values are of the form [lambda, ..., lambda, None, ..., None] 
        and performs a binary search to find the optimal lambda and number of None values.

        Parameters:
        - max_lambda (float): The maximum value for lambda.
        - n_iterations (int, optional): The number of iterations. Default is 20.
        &#34;&#34;&#34;
        super().__init__()
        self.max_lambda = max_lambda
        self.n_iterations = n_iterations

    def compute_lambdas(self, current_optimal_lambdas, execute_function, cost_target, args_execute_function):
        logger.debug(&#34;Computing lambdas with repetitive constant strategy&#34;)
        
        optimal_lambdas = None
        optimal_value = None
        optimal_cost = None
        # Do binary search to find the optimal lambda
        for i in range(len(current_optimal_lambdas)):
            lambda_min = (0, None, None)
            lambda_max = (self.max_lambda, None, None)

            max_lambda = self.max_lambda
            while max_lambda &lt; 1e10:
                lambdas = [max_lambda for _ in range(len(current_optimal_lambdas))]
                output_dict = execute_function(lambdas, *args_execute_function)
                cost = output_dict[&#39;cost&#39;]
                if cost &gt; cost_target:
                    logger.info(f&#39;Max lambda {max_lambda} is too low, increasing max lambda&#39;)
                    lambda_min = (max_lambda, cost, output_dict[&#39;quality&#39;])
                    max_lambda *= 2
                    lambda_max = (max_lambda, None, None)
                else:
                    lambda_max = (max_lambda, cost, output_dict[&#39;quality&#39;])
                    break
            logger.debug(f&#34;Step: {i}&#34;)
            for _ in range(self.n_iterations):
                lambda_mid = (lambda_min[0] + lambda_max[0]) / 2
                logger.debug(f&#34;Lambda mid: {lambda_mid}&#34;)
                lambdas = [lambda_mid if j &lt;= i else None for j in range(len(current_optimal_lambdas))]
                output_dict = execute_function(lambdas, *args_execute_function)
                cost = output_dict[&#39;cost&#39;]

                if cost &lt; cost_target:
                    lambda_max = (lambda_mid, cost, output_dict[&#39;quality&#39;])
                else:
                    lambda_min = (lambda_mid, cost, output_dict[&#39;quality&#39;])
                logger.debug(f&#34;Cost: {cost}&#34;)
                logger.debug(f&#34;Quality: {output_dict[&#39;quality&#39;]}&#34;)

            if optimal_value is None or (lambda_max[2] is not None and lambda_max[2] &gt; optimal_value):
                optimal_lambdas = [lambda_max[0] if j &lt;= i else None for j in range(len(current_optimal_lambdas))]
                optimal_value = lambda_max[2]
                optimal_cost = lambda_max[1]

        logger.info(f&#34;Final Lambda: {optimal_lambdas}&#34;)
        logger.info(f&#34;Final Cost: {optimal_cost}&#34;)
        logger.info(f&#34;Final Quality: {optimal_value}&#34;)
            
        return optimal_lambdas, optimal_cost, optimal_value</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="selection.lambda_strategy.Strategy" href="#selection.lambda_strategy.Strategy">Strategy</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="selection.lambda_strategy.Strategy" href="#selection.lambda_strategy.Strategy">Strategy</a></b></code>:
<ul class="hlist">
<li><code><a title="selection.lambda_strategy.Strategy.compute_lambdas" href="#selection.lambda_strategy.Strategy.compute_lambdas">compute_lambdas</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="selection.lambda_strategy.Strategy"><code class="flex name class">
<span>class <span class="ident">Strategy</span></span>
</code></dt>
<dd>
<div class="desc"><p>Initializes an instance of the Strategy class. These strategies optimize the lambda parameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Strategy:
    def __init__(self):
        &#34;&#34;&#34;
        Initializes an instance of the Strategy class. These strategies optimize the lambda parameters.
        &#34;&#34;&#34;

        pass

    def compute_lambdas(self, current_optimal_lambdas, execute_function, 
                        cost_target, args_execute_function):
        &#34;&#34;&#34;
        Compute the lambdas for model selection.

        Parameters:
        - current_optimal_lambdas (list): The current optimal lambdas in the selection algorithm.
        - execute_function (function): The function to execute for each lambda which returns both cost and quality.
        - cost_target (float): The target cost for model selection.
        - args_execute_function (tuple): The arguments to pass to the execute_function.

        Raises:
        - NotImplementedError: This method is not implemented yet.
        &#34;&#34;&#34;
        raise NotImplementedError</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="selection.lambda_strategy.ConstantStrategy" href="#selection.lambda_strategy.ConstantStrategy">ConstantStrategy</a></li>
<li><a title="selection.lambda_strategy.HyperoptStrategy" href="#selection.lambda_strategy.HyperoptStrategy">HyperoptStrategy</a></li>
<li><a title="selection.lambda_strategy.RepetitiveConstantStrategy" href="#selection.lambda_strategy.RepetitiveConstantStrategy">RepetitiveConstantStrategy</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="selection.lambda_strategy.Strategy.compute_lambdas"><code class="name flex">
<span>def <span class="ident">compute_lambdas</span></span>(<span>self, current_optimal_lambdas, execute_function, cost_target, args_execute_function)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the lambdas for model selection.</p>
<p>Parameters:
- current_optimal_lambdas (list): The current optimal lambdas in the selection algorithm.
- execute_function (function): The function to execute for each lambda which returns both cost and quality.
- cost_target (float): The target cost for model selection.
- args_execute_function (tuple): The arguments to pass to the execute_function.</p>
<p>Raises:
- NotImplementedError: This method is not implemented yet.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="selection" href="index.html">selection</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="selection.lambda_strategy.ConstantStrategy" href="#selection.lambda_strategy.ConstantStrategy">ConstantStrategy</a></code></h4>
</li>
<li>
<h4><code><a title="selection.lambda_strategy.HyperoptStrategy" href="#selection.lambda_strategy.HyperoptStrategy">HyperoptStrategy</a></code></h4>
<ul class="">
<li><code><a title="selection.lambda_strategy.HyperoptStrategy.objective" href="#selection.lambda_strategy.HyperoptStrategy.objective">objective</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="selection.lambda_strategy.RepetitiveConstantStrategy" href="#selection.lambda_strategy.RepetitiveConstantStrategy">RepetitiveConstantStrategy</a></code></h4>
</li>
<li>
<h4><code><a title="selection.lambda_strategy.Strategy" href="#selection.lambda_strategy.Strategy">Strategy</a></code></h4>
<ul class="">
<li><code><a title="selection.lambda_strategy.Strategy.compute_lambdas" href="#selection.lambda_strategy.Strategy.compute_lambdas">compute_lambdas</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.1</a>.</p>
</footer>
</body>
</html>
